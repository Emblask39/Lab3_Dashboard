{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and save .csv with the data of the aircraft crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf = pd.read_csv(\"..\\AccidentesAviones.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pop unwanted columns, in this case \"Unnamed: 0 \" is just an index column I don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf.pop(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns to normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf.rename(columns={\"fecha\": \"date\",\n",
    "                   \"HORA declarada\": \"time\",\n",
    "                   \"Ruta\": \"location\",\n",
    "                   \"OperadOR\": \"Operator\",\n",
    "                   \"PASAJEROS A BORDO\": \"Passangers\",\n",
    "                   \"crew_aboard\": \"crew\",\n",
    "                   \"cantidad de fallecidos\": \"fatalities\",\n",
    "                   }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all \"?\" for None just for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf[crashesdf == \"?\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the \"time\" column to \"hh:mm:ss\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf[\"time\"] = crashesdf[\"time\"].str.replace(\":\",\"\")\n",
    "crashesdf[\"time\"] = crashesdf[\"time\"].str.replace(r\"\\D+\",\"\",regex=True)\n",
    "crashesdf[\"time\"] = pd.to_datetime(crashesdf[\"time\"], format=\"%H%M\").dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to transform the time from format \"hh:mm:ss\" to \"Early Morning\", \"Morning\", \"Noon\", \"Eve\", \"Night\", \"late Night\" for easier comprehension and vizualization in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if (x > \"04:00:00\") and (x <= \"08:00:00\"):\n",
    "        return 'Early Morning'\n",
    "    elif (x > \"08:00:00\") and (x <= \"12:00:00\" ):\n",
    "        return 'Morning'\n",
    "    elif (x > \"12:00:00\") and (x <= \"16:00:00\"):\n",
    "        return'Noon'\n",
    "    elif (x > \"16:00:00\") and (x <= \"20:00:00\") :\n",
    "        return 'Eve'\n",
    "    elif (x > \"20:00:00\") and (x <= \"24:00:00\"):\n",
    "        return'Night'\n",
    "    elif (x <= \"04:00:00\"):\n",
    "        return'Late Night'\n",
    "    elif (x == None):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the previos function to \"time\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf['time'] = crashesdf['time'].astype(str).apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize \"date\" Column to format \"yyyy-mm-dd\" optimal to use in Powerbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf[\"date\"]=pd.to_datetime(crashesdf[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete any line jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesdf = crashesdf.replace(r'\\r','', regex=True)\n",
    "crashesdf = crashesdf.replace(r'\\n','', regex=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataset aicraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"ac_type\", \"registration\", \"IATA\", \"capacity\", \"country\"]\n",
    "aircraftsdf = pd.read_csv(\"..\\\\aircrafts.csv\", names=column_names, sep= \";\")\n",
    "aircraftsdf.replace(\"\\\\N\", None, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataset airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"name\", \"IATA\", \"ICAO\", \"callsign\", \"country\"]\n",
    "airlinesdf = pd.read_csv(\"..\\\\airlines.csv\", names=column_names, sep= \";\")\n",
    "airlinesdf[\"name\"] = airlinesdf[\"name\"].str.split(',').str[1]\n",
    "airlinesdf.replace(\"\\\\N\", None, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export all data in format .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlinesdf.to_csv(\"..\\\\TransformedCSV\\\\airlines.csv\", index=False)\n",
    "aircraftsdf.to_csv(\"..\\\\TransformedCSV\\\\aircrafts.csv\", index=False)\n",
    "crashesdf.to_csv(\"..\\\\TransformedCSV\\crashes.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Wordcloud of each period of time first I accomodate some stopwords related to the \"summary\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = ''\n",
    "stopwords = ['aircraft','plane','the','into','to','of','an','and','by','while','after','in','a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the rows that fulfill the date contitions to each period of time and apply the wordcloud scrypt for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = crashesdf[crashesdf[\"date\"].astype(str) >= \"1914-01-01\"]    \n",
    "df2 = df1[df1[\"date\"].astype(str) < \"1919-12-31\"]\n",
    "\n",
    "for val in df2[\"summary\"]:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 700, height = 1000 ,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10,\n",
    "                max_words=3000).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "fig, ax=plt.subplots(figsize=(9,9))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set(title='World War I Crash Description WordCloud\\n')\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = crashesdf[crashesdf[\"date\"].astype(str) >= \"1929-01-01\"]    \n",
    "df2 = df1[df1[\"date\"].astype(str) < \"1949-12-31\"]\n",
    "\n",
    "for val in df2[\"summary\"]:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 700, height = 1000 ,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10,\n",
    "                max_words=3000).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "fig, ax=plt.subplots(figsize=(9,9))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set(title='Great Depression Crash Description WordCloud\\n')\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = crashesdf[crashesdf[\"date\"].astype(str) >= \"1939-01-01\"]    \n",
    "df2 = df1[df1[\"date\"].astype(str) < \"1945-12-31\"]\n",
    "\n",
    "for val in df2[\"summary\"]:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 700, height = 1000 ,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10,\n",
    "                max_words=3000).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "fig, ax=plt.subplots(figsize=(9,9))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set(title='World War II Crash Description WordCloud\\n')\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = crashesdf[crashesdf[\"date\"].astype(str) >= \"1945-01-01\"]    \n",
    "df2 = df1[df1[\"date\"].astype(str) < \"1980-12-31\"]\n",
    "\n",
    "for val in df2[\"summary\"]:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 700, height = 1000 ,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10,\n",
    "                max_words=3000).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "fig, ax=plt.subplots(figsize=(9,9))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set(title='Post War Crash Description WordCloud\\n')\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = crashesdf[crashesdf[\"date\"].astype(str) >= \"1980-01-01\"]    \n",
    "df2 = df1[df1[\"date\"].astype(str) < \"1999-12-31\"]\n",
    "\n",
    "for val in df2[\"summary\"]:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 700, height = 1000 ,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10,\n",
    "                max_words=3000).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "fig, ax=plt.subplots(figsize=(9,9))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set(title='Digital Age Crash Description WordCloud\\n')\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = crashesdf[crashesdf[\"date\"].astype(str) >= \"2000-01-01\"]    \n",
    "\n",
    "for val in df1[\"summary\"]:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 700, height = 1000 ,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10,\n",
    "                max_words=3000).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "fig, ax=plt.subplots(figsize=(9,9))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set(title='21st Century Crash Description WordCloud\\n')\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(wordcloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
